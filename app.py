import streamlit as st
import requests
import pandas as pd
from rapidfuzz import fuzz, process
import io

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(
    page_title="–°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –≥–æ—Ä–æ–¥–æ–≤ —Å HH.ru",
    page_icon="üåç",
    layout="wide"
)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è session_state
if 'result_df' not in st.session_state:
    st.session_state.result_df = None
if 'duplicate_count' not in st.session_state:
    st.session_state.duplicate_count = 0
if 'processed' not in st.session_state:
    st.session_state.processed = False

# ============================================
# –§–£–ù–ö–¶–ò–ò
# ============================================
@st.cache_data(ttl=3600)
def get_hh_areas():
    """–ü–æ–ª—É—á–∞–µ—Ç —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫ HH.ru"""
    response = requests.get('https://api.hh.ru/areas')
    data = response.json()
    
    areas_dict = {}
    
    def parse_areas(areas, parent_name=""):
        for area in areas:
            area_id = area['id']
            area_name = area['name']
            
            areas_dict[area_name] = {
                'id': area_id,
                'name': area_name,
                'parent': parent_name
            }
            
            if area.get('areas'):
                parse_areas(area['areas'], area_name)
    
    parse_areas(data)
    return areas_dict

def smart_match_city(client_city, hh_city_names, hh_areas, threshold=80):
    """
    –£–º–Ω–æ–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –≥–æ—Ä–æ–¥–∞ —Å —É—á–µ—Ç–æ–º –¥–ª–∏–Ω—ã –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
    """
    # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–ø-5 –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
    candidates = process.extract(
        client_city,
        hh_city_names,
        scorer=fuzz.WRatio,
        limit=5
    )
    
    if not candidates:
        return None
    
    # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –ø–æ—Ä–æ–≥—É
    candidates = [c for c in candidates if c[1] >= threshold]
    
    if not candidates:
        return None
    
    # –ï—Å–ª–∏ —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω –∫–∞–Ω–¥–∏–¥–∞—Ç - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –µ–≥–æ
    if len(candidates) == 1:
        return candidates[0]
    
    # –£–ú–ù–ê–Ø –õ–û–ì–ò–ö–ê: –≤—ã–±–∏—Ä–∞–µ–º –ª—É—á—à–∏–π –≤–∞—Ä–∏–∞–Ω—Ç
    best_match = None
    best_score = 0
    
    client_city_lower = client_city.lower()
    
    for candidate_name, score, _ in candidates:
        candidate_lower = candidate_name.lower()
        
        # –ë–æ–Ω—É—Å–Ω—ã–µ –±–∞–ª–ª—ã –∑–∞:
        adjusted_score = score
        
        # 1. –ë–æ–ª–µ–µ –¥–ª–∏–Ω–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä, "–ñ–µ–ª–µ–∑–Ω–æ–≥–æ—Ä—Å–∫ (–ö—É—Ä—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å)" –ª—É—á—à–µ —á–µ–º "–ö—É—Ä—Å–∫")
        if len(candidate_name) > 10 and len(client_city) > 10:
            adjusted_score += 5
        
        # 2. –¢–æ—á–Ω–æ–µ –≤—Ö–æ–∂–¥–µ–Ω–∏–µ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —Å–ª–æ–≤–∞
        client_words = set(client_city_lower.split())
        candidate_words = set(candidate_lower.replace('(', ' ').replace(')', ' ').split())
        
        # –ï—Å–ª–∏ –ø–µ—Ä–≤–æ–µ —Å–ª–æ–≤–æ –∫–ª–∏–µ–Ω—Ç–∞ –µ—Å—Ç—å –≤ –∫–∞–Ω–¥–∏–¥–∞—Ç–µ - —ç—Ç–æ —Ö–æ—Ä–æ—à–æ
        if client_words and candidate_words:
            first_word_client = list(client_words)[0] if len(list(client_words)[0]) > 3 else None
            if first_word_client and first_word_client in candidate_lower:
                adjusted_score += 10
        
        # 3. –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ "–∫–æ—Ä–æ—Ç–∫–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ" - —à—Ç—Ä–∞—Ñ
        # –ù–∞–ø—Ä–∏–º–µ—Ä, "–ö—É—Ä—Å–∫" –Ω–µ –¥–æ–ª–∂–µ–Ω –ø–æ–±–µ–∂–¥–∞—Ç—å "–ñ–µ–ª–µ–∑–Ω–æ–≥–æ—Ä—Å–∫ (–ö—É—Ä—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å)"
        if len(candidate_name) < len(client_city) * 0.6:
            adjusted_score -= 15
        
        # 4. –ï—Å–ª–∏ –≤ –∫–ª–∏–µ–Ω—Ç–µ –µ—Å—Ç—å –æ–±–ª–∞—Å—Ç—å/–∫—Ä–∞–π, –∞ –≤ –∫–∞–Ω–¥–∏–¥–∞—Ç–µ —Ç–æ–∂–µ - –±–æ–Ω—É—Å
        region_keywords = ['–æ–±–ª–∞—Å—Ç', '–∫—Ä–∞–π', '—Ä–µ—Å–ø—É–±–ª–∏–∫', '–æ–∫—Ä—É–≥']
        client_has_region = any(keyword in client_city_lower for keyword in region_keywords)
        candidate_has_region = any(keyword in candidate_lower for keyword in region_keywords)
        
        if client_has_region and candidate_has_region:
            adjusted_score += 15
        
        if adjusted_score > best_score:
            best_score = adjusted_score
            best_match = (candidate_name, score, _)
    
    return best_match if best_match else candidates[0]

def match_cities(client_cities, hh_areas, threshold=80):
    """–°–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ—Ç –≥–æ—Ä–æ–¥–∞ —Å –¥–≤–æ–π–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–æ–π –¥—É–±–ª–∏–∫–∞—Ç–æ–≤"""
    results = []
    hh_city_names = list(hh_areas.keys())
    
    # –û—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ –∏—Å—Ö–æ–¥–Ω–æ–º—É –Ω–∞–∑–≤–∞–Ω–∏—é
    seen_original_cities = {}
    # –û—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—É HH
    seen_hh_cities = {}
    
    duplicate_original_count = 0
    duplicate_hh_count = 0
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    for idx, client_city in enumerate(client_cities):
        progress = (idx + 1) / len(client_cities)
        progress_bar.progress(progress)
        status_text.text(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {idx + 1} –∏–∑ {len(client_cities)} –≥–æ—Ä–æ–¥–æ–≤...")
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—É—Å—Ç—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
        if pd.isna(client_city) or str(client_city).strip() == "":
            results.append({
                '–ò—Å—Ö–æ–¥–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ': client_city,
                '–ù–∞–∑–≤–∞–Ω–∏–µ HH': None,
                'ID HH': None,
                '–†–µ–≥–∏–æ–Ω': None,
                '–°–æ–≤–ø–∞–¥–µ–Ω–∏–µ %': 0,
                '–°—Ç–∞—Ç—É—Å': '‚ùå –ü—É—Å—Ç–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ'
            })
            continue
        
        client_city_original = str(client_city).strip()
        client_city_normalized = client_city_original.lower().strip()
        
        # –ü–†–û–í–ï–†–ö–ê 1: –î—É–±–ª–∏–∫–∞—Ç –ø–æ –∏—Å—Ö–æ–¥–Ω–æ–º—É –Ω–∞–∑–≤–∞–Ω–∏—é
        if client_city_normalized in seen_original_cities:
            duplicate_original_count += 1
            original_result = seen_original_cities[client_city_normalized]
            results.append({
                '–ò—Å—Ö–æ–¥–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ': client_city_original,
                '–ù–∞–∑–≤–∞–Ω–∏–µ HH': original_result['–ù–∞–∑–≤–∞–Ω–∏–µ HH'],
                'ID HH': original_result['ID HH'],
                '–†–µ–≥–∏–æ–Ω': original_result['–†–µ–≥–∏–æ–Ω'],
                '–°–æ–≤–ø–∞–¥–µ–Ω–∏–µ %': original_result['–°–æ–≤–ø–∞–¥–µ–Ω–∏–µ %'],
                '–°—Ç–∞—Ç—É—Å': 'üîÑ –î—É–±–ª–∏–∫–∞—Ç (–∏—Å—Ö–æ–¥–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ)'
            })
            continue
        
        # –£–º–Ω–æ–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ
        match = smart_match_city(client_city_original, hh_city_names, hh_areas, threshold)
        
        if match:
            matched_name = match[0]
            score = match[1]
            hh_info = hh_areas[matched_name]
            hh_city_normalized = hh_info['name'].lower().strip()
            
            # –ü–†–û–í–ï–†–ö–ê 2: –î—É–±–ª–∏–∫–∞—Ç –ø–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—É HH
            if hh_city_normalized in seen_hh_cities:
                duplicate_hh_count += 1
                city_result = {
                    '–ò—Å—Ö–æ–¥–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ': client_city_original,
                    '–ù–∞–∑–≤–∞–Ω–∏–µ HH': hh_info['name'],
                    'ID HH': hh_info['id'],
                    '–†–µ–≥–∏–æ–Ω': hh_info['parent'],
                    '–°–æ–≤–ø–∞–¥–µ–Ω–∏–µ %': round(score, 1),
                    '–°—Ç–∞—Ç—É—Å': 'üîÑ –î—É–±–ª–∏–∫–∞—Ç (—Ä–µ–∑—É–ª—å—Ç–∞—Ç HH)'
                }
                results.append(city_result)
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ seen_original_cities –¥–ª—è –±—É–¥—É—â–∏—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫
                seen_original_cities[client_city_normalized] = city_result
            else:
                # –£–Ω–∏–∫–∞–ª—å–Ω—ã–π –≥–æ—Ä–æ–¥
                status = '‚úÖ –¢–æ—á–Ω–æ–µ' if score >= 95 else '‚ö†Ô∏è –ü–æ—Ö–æ–∂–µ–µ'
                
                city_result = {
                    '–ò—Å—Ö–æ–¥–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ': client_city_original,
                    '–ù–∞–∑–≤–∞–Ω–∏–µ HH': hh_info['name'],
                    'ID HH': hh_info['id'],
                    '–†–µ–≥–∏–æ–Ω': hh_info['parent'],
                    '–°–æ–≤–ø–∞–¥–µ–Ω–∏–µ %': round(score, 1),
                    '–°—Ç–∞—Ç—É—Å': status
                }
                
                results.append(city_result)
                seen_original_cities[client_city_normalized] = city_result
                seen_hh_cities[hh_city_normalized] = True
        else:
            # –ù–µ –Ω–∞–π–¥–µ–Ω–æ
            city_result = {
                '–ò—Å—Ö–æ–¥–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ': client_city_original,
                '–ù–∞–∑–≤–∞–Ω–∏–µ HH': None,
                'ID HH': None,
                '–†–µ–≥–∏–æ–Ω': None,
                '–°–æ–≤–ø–∞–¥–µ–Ω–∏–µ %': 0,
                '–°—Ç–∞—Ç—É—Å': '‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ'
            }
            
            results.append(city_result)
            seen_original_cities[client_city_normalized] = city_result
    
    progress_bar.empty()
    status_text.empty()
    
    total_duplicates = duplicate_original_count + duplicate_hh_count
    
    return pd.DataFrame(results), duplicate_original_count, duplicate_hh_count, total_duplicates

# ============================================
# –ò–ù–¢–ï–†–§–ï–ô–°
# ============================================

st.title("üåç –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –≥–æ—Ä–æ–¥–æ–≤ —Å HH.ru")
st.markdown("---")

# –ë–æ–∫–æ–≤–∞—è –ø–∞–Ω–µ–ª—å
with st.sidebar:
    st.header("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏")
    threshold = st.slider(
        "–ü–æ—Ä–æ–≥ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è (%)",
        min_value=50,
        max_value=100,
        value=80,
        help="–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø—Ä–æ—Ü–µ–Ω—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è"
    )
    
    st.markdown("---")
    st.markdown("### üìñ –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è")
    st.markdown("""
    1. –ó–∞–≥—Ä—É–∑–∏—Ç–µ Excel –∏–ª–∏ CSV
    2. –ì–æ—Ä–æ–¥–∞ –≤ –ø–µ—Ä–≤–æ–π –∫–æ–ª–æ–Ω–∫–µ
    3. –ù–∞–∂–º–∏—Ç–µ "–ù–∞—á–∞—Ç—å"
    4. –°–∫–∞—á–∞–π—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    """)
    
    st.markdown("---")
    st.markdown("### üìä –°—Ç–∞—Ç—É—Å—ã")
    st.markdown("""
    - ‚úÖ **–¢–æ—á–Ω–æ–µ** - —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ ‚â•95%
    - ‚ö†Ô∏è **–ü–æ—Ö–æ–∂–µ–µ** - —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ ‚â•–ø–æ—Ä–æ–≥–∞
    - üîÑ **–î—É–±–ª–∏–∫–∞—Ç (–∏—Å—Ö–æ–¥–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ)** - –ø–æ–≤—Ç–æ—Ä –≤ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–º —Ñ–∞–π–ª–µ
    - üîÑ **–î—É–±–ª–∏–∫–∞—Ç (—Ä–µ–∑—É–ª—å—Ç–∞—Ç HH)** - —Ä–∞–∑–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è ‚Üí –æ–¥–∏–Ω –≥–æ—Ä–æ–¥ HH
    - ‚ùå **–ù–µ –Ω–∞–π–¥–µ–Ω–æ** - —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ <–ø–æ—Ä–æ–≥–∞
    """)
    
    st.markdown("---")
    st.info("""
    üí° **–£–º–Ω—ã–π –ø–æ–∏—Å–∫:**
    
    –°–∏—Å—Ç–µ–º–∞ —É—á–∏—Ç—ã–≤–∞–µ—Ç:
    - –î–ª–∏–Ω—É –Ω–∞–∑–≤–∞–Ω–∏—è
    - –ù–∞–ª–∏—á–∏–µ –æ–±–ª–∞—Å—Ç–∏/–∫—Ä–∞—è
    - –¢–æ—á–Ω–æ—Å—Ç—å —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è —Å–ª–æ–≤
    
    –ü—Ä–∏–º–µ—Ä: "–ñ–µ–ª–µ–∑–Ω–æ–≥–æ—Ä—Å–∫ –ö—É—Ä—Å–∫–æ–π –æ–±–ª–∞—Å—Ç–∏" ‚Üí "–ñ–µ–ª–µ–∑–Ω–æ–≥–æ—Ä—Å–∫ (–ö—É—Ä—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å)" ‚úÖ
    """)

# –û—Å–Ω–æ–≤–Ω–∞—è –æ–±–ª–∞—Å—Ç—å
col1, col2 = st.columns([1, 1])

with col1:
    st.subheader("üì§ –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞")
    uploaded_file = st.file_uploader(
        "–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–∞–π–ª —Å –≥–æ—Ä–æ–¥–∞–º–∏",
        type=['xlsx', 'csv'],
        help="–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è —Ñ–æ—Ä–º–∞—Ç—ã: Excel (.xlsx) –∏ CSV"
    )
    
    with st.expander("üìã –ü–æ–∫–∞–∑–∞—Ç—å –ø—Ä–∏–º–µ—Ä —Ñ–æ—Ä–º–∞—Ç–∞ —Ñ–∞–π–ª–∞"):
        example_df = pd.DataFrame({
            '–ì–æ—Ä–æ–¥': ['–ú–æ—Å–∫–≤–∞', '–ü–∏—Ç–µ—Ä', '–ï–∫–∞—Ç–µ—Ä–∏–Ω–±—É—Ä–≥', '–ù–æ–≤–æ—Å–∏–±']
        })
        st.dataframe(example_df, use_container_width=True)

with col2:
    st.subheader("‚ÑπÔ∏è –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è")
    try:
        hh_areas = get_hh_areas()
        st.success(f"‚úÖ –°–ø—Ä–∞–≤–æ—á–Ω–∏–∫ HH –∑–∞–≥—Ä—É–∂–µ–Ω: **{len(hh_areas)}** –≥–æ—Ä–æ–¥–æ–≤")
    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∞: {str(e)}")
        hh_areas = None

# –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞
if uploaded_file is not None and hh_areas is not None:
    st.markdown("---")
    
    try:
        # –ß—Ç–µ–Ω–∏–µ —Ñ–∞–π–ª–∞
        if uploaded_file.name.endswith('.csv'):
            df = pd.read_csv(uploaded_file)
        else:
            df = pd.read_excel(uploaded_file)
        
        client_cities = df.iloc[:, 0].tolist()
        st.info(f"üìÑ –ó–∞–≥—Ä—É–∂–µ–Ω–æ **{len(client_cities)}** –≥–æ—Ä–æ–¥–æ–≤ –∏–∑ —Ñ–∞–π–ª–∞")
        
        # –ö–Ω–æ–ø–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        if st.button("üöÄ –ù–∞—á–∞—Ç—å —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ", type="primary", use_container_width=True):
            with st.spinner("–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é..."):
                result_df, dup_original, dup_hh, total_dup = match_cities(client_cities, hh_areas, threshold)
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ session_state
                st.session_state.result_df = result_df
                st.session_state.dup_original = dup_original
                st.session_state.dup_hh = dup_hh
                st.session_state.total_dup = total_dup
                st.session_state.processed = True
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã, –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å –≤ session_state
        if st.session_state.processed and st.session_state.result_df is not None:
            result_df = st.session_state.result_df
            dup_original = st.session_state.dup_original
            dup_hh = st.session_state.dup_hh
            total_dup = st.session_state.total_dup
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            st.markdown("---")
            st.subheader("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã")
            
            col1, col2, col3, col4, col5 = st.columns(5)
            
            total = len(result_df)
            exact = len(result_df[result_df['–°—Ç–∞—Ç—É—Å'] == '‚úÖ –¢–æ—á–Ω–æ–µ'])
            similar = len(result_df[result_df['–°—Ç–∞—Ç—É—Å'] == '‚ö†Ô∏è –ü–æ—Ö–æ–∂–µ–µ'])
            duplicates = len(result_df[result_df['–°—Ç–∞—Ç—É—Å'].str.contains('–î—É–±–ª–∏–∫–∞—Ç', na=False)])
            not_found = len(result_df[result_df['–°—Ç–∞—Ç—É—Å'] == '‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ'])
            
            col1.metric("–í—Å–µ–≥–æ", total)
            col2.metric("‚úÖ –¢–æ—á–Ω—ã—Ö", exact, f"{exact/total*100:.1f}%")
            col3.metric("‚ö†Ô∏è –ü–æ—Ö–æ–∂–∏—Ö", similar, f"{similar/total*100:.1f}%")
            col4.metric("üîÑ –î—É–±–ª–∏–∫–∞—Ç–æ–≤", duplicates, f"{duplicates/total*100:.1f}%")
            col5.metric("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ", not_found, f"{not_found/total*100:.1f}%")
            
            # –î–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥—É–±–ª–∏–∫–∞—Ç–∞—Ö
            if duplicates > 0:
                st.warning(f"""
                ‚ö†Ô∏è **–ù–∞–π–¥–µ–Ω–æ {duplicates} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤:**
                - üîÑ –ü–æ –∏—Å—Ö–æ–¥–Ω–æ–º—É –Ω–∞–∑–≤–∞–Ω–∏—é: **{dup_original}**
                - üîÑ –ü–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—É HH: **{dup_hh}**
                
                –í—Å–µ –¥—É–±–ª–∏–∫–∞—Ç—ã –±—É–¥—É—Ç –∏—Å–∫–ª—é—á–µ–Ω—ã –∏–∑ —Ñ–∞–π–ª–∞ –¥–ª—è –ø—É–±–ª–∏–∫–∞—Ç–æ—Ä–∞.
                """)
            
            # –¢–∞–±–ª–∏—Ü–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            st.markdown("---")
            st.subheader("üìã –¢–∞–±–ª–∏—Ü–∞ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–π")
            
            # –§–∏–ª—å—Ç—Ä—ã
            filter_col1, filter_col2 = st.columns(2)
            
            with filter_col1:
                status_filter = st.multiselect(
                    "–§–∏–ª—å—Ç—Ä –ø–æ —Å—Ç–∞—Ç—É—Å—É",
                    options=[
                        '‚úÖ –¢–æ—á–Ω–æ–µ', 
                        '‚ö†Ô∏è –ü–æ—Ö–æ–∂–µ–µ', 
                        'üîÑ –î—É–±–ª–∏–∫–∞—Ç (–∏—Å—Ö–æ–¥–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ)',
                        'üîÑ –î—É–±–ª–∏–∫–∞—Ç (—Ä–µ–∑—É–ª—å—Ç–∞—Ç HH)',
                        '‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ'
                    ],
                    default=[
                        '‚úÖ –¢–æ—á–Ω–æ–µ', 
                        '‚ö†Ô∏è –ü–æ—Ö–æ–∂–µ–µ', 
                        'üîÑ –î—É–±–ª–∏–∫–∞—Ç (–∏—Å—Ö–æ–¥–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ)',
                        'üîÑ –î—É–±–ª–∏–∫–∞—Ç (—Ä–µ–∑—É–ª—å—Ç–∞—Ç HH)',
                        '‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ'
                    ],
                    key='status_filter'
                )
            
            with filter_col2:
                search_term = st.text_input("üîç –ü–æ–∏—Å–∫ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é", "", key='search_input')
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–∏–ª—å—Ç—Ä—ã
            filtered_df = result_df[result_df['–°—Ç–∞—Ç—É—Å'].isin(status_filter)]
            
            if search_term:
                filtered_df = filtered_df[
                    filtered_df['–ò—Å—Ö–æ–¥–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ'].str.contains(search_term, case=False, na=False) |
                    filtered_df['–ù–∞–∑–≤–∞–Ω–∏–µ HH'].str.contains(search_term, case=False, na=False)
                ]
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–∞–±–ª–∏—Ü—É
            st.dataframe(
                filtered_df,
                use_container_width=True,
                height=400
            )
            
            # –°–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            st.markdown("---")
            st.subheader("üíæ –°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã")
            
            col1, col2 = st.columns(2)
            
            # –ü–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç Excel
            with col1:
                output = io.BytesIO()
                with pd.ExcelWriter(output, engine='openpyxl') as writer:
                    result_df.to_excel(writer, index=False, sheet_name='–†–µ–∑—É–ª—å—Ç–∞—Ç')
                output.seek(0)
                
                st.download_button(
                    label="üì• –°–∫–∞—á–∞—Ç—å –ø–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç (Excel)",
                    data=output,
                    file_name=f"result_{uploaded_file.name.rsplit('.', 1)[0]}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    use_container_width=True,
                    key='download_full'
                )
            
            # –§–∞–π–ª –¥–ª—è –ø—É–±–ª–∏–∫–∞—Ç–æ—Ä–∞ (—Ç–æ–ª—å–∫–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –≥–µ–æ –ë–ï–ó –∑–∞–≥–æ–ª–æ–≤–∫–∞)
            with col2:
                # –ò—Å–∫–ª—é—á–∞–µ–º –í–°–ï –¥—É–±–ª–∏–∫–∞—Ç—ã (–æ–±–∞ —Ç–∏–ø–∞)
                unique_df = result_df[~result_df['–°—Ç–∞—Ç—É—Å'].str.contains('–î—É–±–ª–∏–∫–∞—Ç', na=False)]
                
                # –°–æ–∑–¥–∞–µ–º DataFrame —Ç–æ–ª—å–∫–æ —Å –∫–æ–ª–æ–Ω–∫–æ–π "–ù–∞–∑–≤–∞–Ω–∏–µ HH"
                publisher_df = pd.DataFrame({
                    '–ù–∞–∑–≤–∞–Ω–∏–µ HH': unique_df['–ù–∞–∑–≤–∞–Ω–∏–µ HH']
                })
                
                # –£–¥–∞–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏ —Å None (–≥–æ—Ä–æ–¥–∞, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã)
                publisher_df = publisher_df.dropna()
                
                output_publisher = io.BytesIO()
                with pd.ExcelWriter(output_publisher, engine='openpyxl') as writer:
                    # header=False —É–±–∏—Ä–∞–µ—Ç –∑–∞–≥–æ–ª–æ–≤–æ–∫
                    publisher_df.to_excel(writer, index=False, header=False, sheet_name='–ì–µ–æ')
                output_publisher.seek(0)
                
                unique_count = len(publisher_df)
                
                st.download_button(
                    label=f"üì§ –í—ã–≥—Ä—É–∑–∏—Ç—å –≥–æ—Ç–æ–≤—ã–π —Ñ–∞–π–ª –¥–ª—è –ø—É–±–ª–∏–∫–∞—Ç–æ—Ä–∞ ({unique_count} –≥–æ—Ä–æ–¥–æ–≤)",
                    data=output_publisher,
                    file_name=f"geo_for_publisher_{uploaded_file.name.rsplit('.', 1)[0]}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    use_container_width=True,
                    type="primary",
                    key='download_publisher'
                )
            
    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞: {str(e)}")

# –§—É—Ç–µ—Ä
st.markdown("---")
st.markdown(
    "<div style='text-align: center; color: gray;'>–°–¥–µ–ª–∞–Ω–æ —Å ‚ù§Ô∏è | –î–∞–Ω–Ω—ã–µ –∏–∑ API HH.ru</div>",
    unsafe_allow_html=True
)
