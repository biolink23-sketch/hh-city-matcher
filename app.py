import streamlit as st
import requests
import pandas as pd
from rapidfuzz import fuzz, process
import io

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(
    page_title="–°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ç–æ—Ä –≥–µ–æ HH.ru",
    page_icon="üåç",
    layout="wide"
)

# CSS –¥–ª—è –∞–Ω–∏–º–∞—Ü–∏–∏ –∑–µ–º–ª–∏ –∏ —Å—Ç–∏–ª–µ–π
st.markdown("""
<style>
@keyframes rotate {
    from { transform: rotate(0deg); }
    to { transform: rotate(360deg); }
}

.rotating-earth {
    display: inline-block;
    animation: rotate 3s linear infinite;
    font-size: 3em;
    vertical-align: middle;
    margin-right: 15px;
}

.main-title {
    display: inline-block;
    font-size: 3em;
    font-weight: bold;
    vertical-align: middle;
    margin: 0;
}

.title-container {
    display: flex;
    align-items: center;
    margin-bottom: 20px;
}
</style>
""", unsafe_allow_html=True)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è session_state
if 'result_df' not in st.session_state:
    st.session_state.result_df = None
if 'duplicate_count' not in st.session_state:
    st.session_state.duplicate_count = 0
if 'processed' not in st.session_state:
    st.session_state.processed = False
if 'manual_selections' not in st.session_state:
    st.session_state.manual_selections = {}
if 'candidates_cache' not in st.session_state:
    st.session_state.candidates_cache = {}
if 'search_query' not in st.session_state:
    st.session_state.search_query = ""

# ============================================
# –§–£–ù–ö–¶–ò–ò
# ============================================
@st.cache_data(ttl=3600)
def get_hh_areas():
    """–ü–æ–ª—É—á–∞–µ—Ç —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫ HH.ru"""
    response = requests.get('https://api.hh.ru/areas')
    data = response.json()
    
    areas_dict = {}
    
    def parse_areas(areas, parent_name=""):
        for area in areas:
            area_id = area['id']
            area_name = area['name']
            
            areas_dict[area_name] = {
                'id': area_id,
                'name': area_name,
                'parent': parent_name
            }
            
            if area.get('areas'):
                parse_areas(area['areas'], area_name)
    
    parse_areas(data)
    return areas_dict

def normalize_region_name(text):
    """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ —Ä–µ–≥–∏–æ–Ω–∞ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è"""
    text = text.lower()
    replacements = {
        '–ª–µ–Ω–∏–Ω–≥—Ä–∞–¥—Å–∫–∞—è': '–ª–µ–Ω–∏–Ω–≥—Ä–∞–¥',
        '–º–æ—Å–∫–æ–≤—Å–∫–∞—è': '–º–æ—Å–∫–æ–≤',
        '–∫—É—Ä—Å–∫–∞—è': '–∫—É—Ä—Å–∫',
        '–∫–µ–º–µ—Ä–æ–≤—Å–∫–∞—è': '–∫–µ–º–µ—Ä–æ–≤',
        '—Å–≤–µ—Ä–¥–ª–æ–≤—Å–∫–∞—è': '—Å–≤–µ—Ä–¥–ª–æ–≤',
        '–Ω–∏–∂–µ–≥–æ—Ä–æ–¥—Å–∫–∞—è': '–Ω–∏–∂–µ–≥–æ—Ä–æ–¥',
        '–Ω–æ–≤–æ—Å–∏–±–∏—Ä—Å–∫–∞—è': '–Ω–æ–≤–æ—Å–∏–±–∏—Ä—Å–∫',
        '—Ç–∞–º–±–æ–≤—Å–∫–∞—è': '—Ç–∞–º–±–æ–≤',
        '–∫—Ä–∞—Å–Ω–æ—è—Ä—Å–∫–∞—è': '–∫—Ä–∞—Å–Ω–æ—è—Ä—Å–∫',
        '–æ–±–ª–∞—Å—Ç—å': '',
        '–æ–±–ª': '',
        '–∫—Ä–∞–π': '',
        '—Ä–µ—Å–ø—É–±–ª–∏–∫–∞': '',
        '—Ä–µ—Å–ø': '',
        '  ': ' '
    }
    for old, new in replacements.items():
        text = text.replace(old, new)
    return text.strip()

def extract_city_and_region(text):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ –≥–æ—Ä–æ–¥–∞ –∏ —Ä–µ–≥–∏–æ–Ω–∞ –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
    text_lower = text.lower()
    
    region_keywords = [
        '–æ–±–ª–∞—Å—Ç', '–∫—Ä–∞–π', '—Ä–µ—Å–ø—É–±–ª–∏–∫', '–æ–∫—Ä—É–≥',
        '–ª–µ–Ω–∏–Ω–≥—Ä–∞–¥', '–º–æ—Å–∫–æ–≤', '–∫—É—Ä—Å–∫', '–∫–µ–º–µ—Ä–æ–≤',
        '—Å–≤–µ—Ä–¥–ª–æ–≤', '–Ω–∏–∂–µ–≥–æ—Ä–æ–¥', '–Ω–æ–≤–æ—Å–∏–±–∏—Ä—Å–∫', '—Ç–∞–º–±–æ–≤',
        '–∫—Ä–∞—Å–Ω–æ—è—Ä—Å–∫'
    ]
    
    words = text.split()
    
    if len(words) == 1:
        return text, None
    
    city_words = []
    region_words = []
    region_found = False
    
    for word in words:
        word_lower = word.lower()
        if not region_found and any(keyword in word_lower for keyword in region_keywords):
            region_found = True
            region_words.append(word)
        elif region_found:
            region_words.append(word)
        else:
            city_words.append(word)
    
    city = ' '.join(city_words) if city_words else text
    region = ' '.join(region_words) if region_words else None
    
    return city, region

def check_if_changed(original, matched):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –∏–∑–º–µ–Ω–∏–ª–æ—Å—å –ª–∏ –Ω–∞–∑–≤–∞–Ω–∏–µ –≥–æ—Ä–æ–¥–∞"""
    if matched is None or matched == "‚ùå –ù–µ—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è":
        return False
    
    original_clean = original.strip()
    matched_clean = matched.strip()
    
    return original_clean != matched_clean

def get_candidates_by_word(client_city, hh_city_names, limit=20):
    """–ü–æ–ª—É—á–∞–µ—Ç –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –ø–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—é –Ω–∞—á–∞–ª—å–Ω–æ–≥–æ —Å–ª–æ–≤–∞"""
    first_word = client_city.split()[0].lower().strip()
    candidates = []
    for city_name in hh_city_names:
        city_lower = city_name.lower()
        if first_word in city_lower:
            score = fuzz.WRatio(client_city.lower(), city_lower)
            candidates.append((city_name, score))
    candidates.sort(key=lambda x: x[1], reverse=True)
    return candidates[:limit]

def smart_match_city(client_city, hh_city_names, hh_areas, threshold=85):
    """–£–º–Ω–æ–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –≥–æ—Ä–æ–¥–∞"""
    city_part, _ = extract_city_and_region(client_city)
    city_part_lower = city_part.lower().strip()
    
    # –°–Ω–∞—á–∞–ª–∞ –∏—â–µ–º –ø–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞–º
    word_candidates = get_candidates_by_word(client_city, hh_city_names)
    if word_candidates and word_candidates[0][1] >= threshold:
        best_candidate = word_candidates[0]
        return (best_candidate[0], best_candidate[1], 0), word_candidates
    
    # –ï—Å–ª–∏ fuzzy –ø–æ–∏—Å–∫ RapidFuzz –Ω–∞—Ö–æ–¥–∏—Ç —á—Ç–æ-—Ç–æ –ª—É—á—à–µ
    best_match = process.extractOne(client_city, hh_city_names, scorer=fuzz.WRatio)
    if best_match and best_match[1] >= threshold:
        return best_match, word_candidates
        
    return None, word_candidates

def match_cities(client_cities, hh_areas, threshold=85):
    """–°–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ—Ç –≥–æ—Ä–æ–¥–∞"""
    results = []
    hh_city_names = list(hh_areas.keys())
    seen_original_cities, seen_hh_cities = {}, {}
    dup_original, dup_hh = 0, 0
    st.session_state.candidates_cache = {}
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    for idx, client_city in enumerate(client_cities):
        progress_bar.progress((idx + 1) / len(client_cities))
        status_text.text(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {idx + 1} –∏–∑ {len(client_cities)} –≥–æ—Ä–æ–¥–æ–≤...")
        
        if pd.isna(client_city) or str(client_city).strip() == "":
            results.append({'–ò—Å—Ö–æ–¥–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ': client_city, '–ò—Ç–æ–≥–æ–≤–æ–µ –≥–µ–æ': None, 'ID HH': None, '–†–µ–≥–∏–æ–Ω': None, '–°–æ–≤–ø–∞–¥–µ–Ω–∏–µ %': 0, '–ò–∑–º–µ–Ω–µ–Ω–∏–µ': '–ù–µ—Ç', '–°—Ç–∞—Ç—É—Å': '‚ùå –ü—É—Å—Ç–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ', 'row_id': idx})
            continue
        
        client_city_original = str(client_city).strip()
        match_result, candidates = smart_match_city(client_city_original, hh_city_names, hh_areas, threshold)
        st.session_state.candidates_cache[idx] = candidates
        
        if match_result:
            matched_name, score = match_result[0], match_result[1]
            hh_info = hh_areas[matched_name]
            change_status = '–î–∞' if check_if_changed(client_city_original, hh_info['name']) else '–ù–µ—Ç'
            status = '‚úÖ –¢–æ—á–Ω–æ–µ' if score >= 95 else '‚ö†Ô∏è –ü–æ—Ö–æ–∂–µ–µ'
            
            city_result = {'–ò—Å—Ö–æ–¥–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ': client_city_original, '–ò—Ç–æ–≥–æ–≤–æ–µ –≥–µ–æ': hh_info['name'], 'ID HH': hh_info['id'], '–†–µ–≥–∏–æ–Ω': hh_info['parent'], '–°–æ–≤–ø–∞–¥–µ–Ω–∏–µ %': round(score, 1), '–ò–∑–º–µ–Ω–µ–Ω–∏–µ': change_status, '–°—Ç–∞—Ç—É—Å': status, 'row_id': idx}
            results.append(city_result)
        else:
            results.append({'–ò—Å—Ö–æ–¥–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ': client_city_original, '–ò—Ç–æ–≥–æ–≤–æ–µ –≥–µ–æ': None, 'ID HH': None, '–†–µ–≥–∏–æ–Ω': None, '–°–æ–≤–ø–∞–¥–µ–Ω–∏–µ %': 0, '–ò–∑–º–µ–Ω–µ–Ω–∏–µ': '–ù–µ—Ç', '–°—Ç–∞—Ç—É—Å': '‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ', 'row_id': idx})
    
    progress_bar.empty()
    status_text.empty()
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –ø–æ—Å–ª–µ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —Ü–∏–∫–ª–∞ –¥–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã
    df_res = pd.DataFrame(results)
    df_res['is_duplicate_source'] = df_res.duplicated('–ò—Å—Ö–æ–¥–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ', keep='first')
    df_res['is_duplicate_hh'] = df_res.duplicated('–ò—Ç–æ–≥–æ–≤–æ–µ –≥–µ–æ', keep='first') & df_res['–ò—Ç–æ–≥–æ–≤–æ–µ –≥–µ–æ'].notna()
    
    dup_original = df_res['is_duplicate_source'].sum()
    dup_hh = df_res[~df_res['is_duplicate_source']]['is_duplicate_hh'].sum()
    
    df_res.loc[df_res['is_duplicate_source'], '–°—Ç–∞—Ç—É—Å'] = 'üîÑ –î—É–±–ª–∏–∫–∞—Ç (–∏—Å—Ö–æ–¥–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ)'
    df_res.loc[~df_res['is_duplicate_source'] & df_res['is_duplicate_hh'], '–°—Ç–∞—Ç—É—Å'] = 'üîÑ –î—É–±–ª–∏–∫–∞—Ç (—Ä–µ–∑—É–ª—å—Ç–∞—Ç HH)'
    
    df_res = df_res.drop(columns=['is_duplicate_source', 'is_duplicate_hh'])
    
    return df_res, dup_original, dup_hh, dup_original + dup_hh

# ============================================
# –ò–ù–¢–ï–†–§–ï–ô–°
# ============================================
st.markdown(
    '<div class="title-container">'
    '<span class="rotating-earth">üåç</span>'
    '<span class="main-title">–°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ç–æ—Ä –≥–µ–æ HH.ru</span>'
    '</div>',
    unsafe_allow_html=True
)
st.markdown("---")

with st.sidebar:
    st.header("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏")
    threshold = st.slider("–ü–æ—Ä–æ–≥ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è (%)", 50, 100, 85)
    st.markdown("---")
    st.markdown("### üìñ –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è")
    st.markdown("1. **–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª** Excel –∏–ª–∏ CSV —Å –≥–æ—Ä–æ–¥–∞–º–∏.\n"
                "2. –ì–æ—Ä–æ–¥–∞ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –≤ **–ø–µ—Ä–≤–æ–π –∫–æ–ª–æ–Ω–∫–µ**.\n"
                "3. –ù–∞–∂–º–∏—Ç–µ **'üöÄ –ù–∞—á–∞—Ç—å —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ'**.\n"
                "4. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏ –æ—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä—É–π—Ç–µ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏.\n"
                "5. –°–∫–∞—á–∞–π—Ç–µ –∏—Ç–æ–≥–æ–≤—ã–π —Ñ–∞–π–ª.")
    st.markdown("---")
    with st.expander("üìö –ü–æ–ª–Ω–∞—è —Å–ø—Ä–∞–≤–∫–∞ –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é", expanded=False):
        st.markdown("–ü–æ–¥—Ä–æ–±–Ω–∞—è —Å–ø—Ä–∞–≤–∫–∞...") # –°–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å–ø—Ä–∞–≤–∫–∏ –æ—Å—Ç–∞–≤–ª–µ–Ω–æ –¥–ª—è –∫—Ä–∞—Ç–∫–æ—Å—Ç–∏

col1, col2 = st.columns([1, 1])

with col1:
    st.subheader("üì§ –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞")
    uploaded_file = st.file_uploader("–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–∞–π–ª —Å –≥–æ—Ä–æ–¥–∞–º–∏", type=['xlsx', 'csv'])
    with st.expander("üìã –ü–æ–∫–∞–∑–∞—Ç—å –ø—Ä–∏–º–µ—Ä —Ñ–æ—Ä–º–∞—Ç–∞ —Ñ–∞–π–ª–∞"):
        example_df = pd.DataFrame({'–ì–æ—Ä–æ–¥–∞': ['–ú–æ—Å–∫–≤–∞', '–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥', '–ö–∏—Ä–æ–≤—Å–∫ –õ–µ–Ω–∏–Ω–≥—Ä–∞–¥—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å']})
        # –ò–ó–ú–ï–ù–ï–ù–ò–ï: –ó–∞–º–µ–Ω–∞ st.dataframe –Ω–∞ st.data_editor –¥–ª—è —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è
        st.data_editor(example_df, use_container_width=True, hide_index=True, disabled=True)

with col2:
    st.subheader("‚ÑπÔ∏è –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è")
    try:
        hh_areas = get_hh_areas()
        st.success(f"‚úÖ –°–ø—Ä–∞–≤–æ—á–Ω–∏–∫ HH –∑–∞–≥—Ä—É–∂–µ–Ω: **{len(hh_areas)}** –≥–æ—Ä–æ–¥–æ–≤")
    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∞: {str(e)}")
        hh_areas = None

if uploaded_file is not None and hh_areas is not None:
    st.markdown("---")
    try:
        df = pd.read_excel(uploaded_file) if uploaded_file.name.endswith('.xlsx') else pd.read_csv(uploaded_file)
        client_cities = df.iloc[:, 0].dropna().tolist()
        st.info(f"üìÑ –ó–∞–≥—Ä—É–∂–µ–Ω–æ **{len(client_cities)}** –≥–æ—Ä–æ–¥–æ–≤ –∏–∑ —Ñ–∞–π–ª–∞")
        
        if st.button("üöÄ –ù–∞—á–∞—Ç—å —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ", type="primary", use_container_width=True):
            with st.spinner("–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é..."):
                result_df, dup_original, dup_hh, total_dup = match_cities(client_cities, hh_areas, threshold)
                st.session_state.result_df = result_df
                st.session_state.dup_original = dup_original
                st.session_state.dup_hh = dup_hh
                st.session_state.processed = True
                st.session_state.manual_selections = {}
        
        if st.session_state.processed and st.session_state.result_df is not None:
            result_df = st.session_state.result_df.copy()
            
            st.markdown("---")
            st.subheader("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã")
            
            to_export = len(result_df[~result_df['–°—Ç–∞—Ç—É—Å'].str.contains('–î—É–±–ª–∏–∫–∞—Ç', na=False) & result_df['–ò—Ç–æ–≥–æ–≤–æ–µ –≥–µ–æ'].notna()])
            
            col1, col2, col3, col4, col5, col6 = st.columns(6)
            col1.metric("–í—Å–µ–≥–æ", len(result_df))
            col2.metric("‚úÖ –¢–æ—á–Ω—ã—Ö", len(result_df[result_df['–°—Ç–∞—Ç—É—Å'] == '‚úÖ –¢–æ—á–Ω–æ–µ']))
            col3.metric("‚ö†Ô∏è –ü–æ—Ö–æ–∂–∏—Ö", len(result_df[result_df['–°—Ç–∞—Ç—É—Å'] == '‚ö†Ô∏è –ü–æ—Ö–æ–∂–µ–µ']))
            col4.metric("üîÑ –î—É–±–ª–∏–∫–∞—Ç–æ–≤", len(result_df[result_df['–°—Ç–∞—Ç—É—Å'].str.contains('–î—É–±–ª–∏–∫–∞—Ç', na=False)]))
            col5.metric("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ", len(result_df[result_df['–°—Ç–∞—Ç—É—Å'] == '‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ']))
            col6.metric("üì§ –ö –≤—ã–≥—Ä—É–∑–∫–µ", to_export)

            st.markdown("---")
            st.subheader("üìã –¢–∞–±–ª–∏—Ü–∞ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–π")
            
            # –í–æ–∑–≤—Ä–∞—â–µ–Ω —Å—Ç–∞–±–∏–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ Enter
            search_query = st.text_input("üîç –ü–æ–∏—Å–∫ –ø–æ —Ç–∞–±–ª–∏—Ü–µ (–Ω–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è)")
            
            result_df_sorted = result_df.sort_values(by=['–°–æ–≤–ø–∞–¥–µ–Ω–∏–µ %']).reset_index(drop=True)
            
            if search_query:
                search_lower = search_query.lower()
                mask = result_df_sorted.apply(lambda row: any(search_lower in str(val).lower() for val in row.values), axis=1)
                result_df_filtered = result_df_sorted[mask]
            else:
                result_df_filtered = result_df_sorted

            display_df = result_df_filtered.drop(['row_id'], axis=1, errors='ignore')
            # –ò–ó–ú–ï–ù–ï–ù–ò–ï: –ó–∞–º–µ–Ω–∞ st.dataframe –Ω–∞ st.data_editor –¥–ª—è —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è
            st.data_editor(display_df, use_container_width=True, height=400, disabled=True)

            editable_rows = result_df[result_df['–°–æ–≤–ø–∞–¥–µ–Ω–∏–µ %'] <= 90].copy()
            if not editable_rows.empty:
                st.markdown("---")
                st.subheader("‚úèÔ∏è –†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≥–æ—Ä–æ–¥–æ–≤ —Å —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ–º ‚â§ 90%")
                for _, row in editable_rows.iterrows():
                    row_id = row['row_id']
                    candidates = st.session_state.candidates_cache.get(row_id, [])
                    options = ["‚ùå –ù–µ—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è"] + [c[0] for c in candidates]
                    
                    current_selection = st.session_state.manual_selections.get(row_id, row['–ò—Ç–æ–≥–æ–≤–æ–µ –≥–µ–æ'])
                    default_idx = options.index(current_selection) if current_selection in options else 0

                    selected = st.selectbox(f"**{row['–ò—Å—Ö–æ–¥–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ']}**", options, index=default_idx, key=f"select_{row_id}")
                    st.session_state.manual_selections[row_id] = selected

            st.markdown("---")
            st.subheader("üíæ –°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã")
            final_result_df = result_df.copy()
            if st.session_state.manual_selections:
                for row_id, new_value in st.session_state.manual_selections.items():
                    mask = final_result_df['row_id'] == row_id
                    if new_value == "‚ùå –ù–µ—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è":
                        final_result_df.loc[mask, ['–ò—Ç–æ–≥–æ–≤–æ–µ –≥–µ–æ', 'ID HH', '–†–µ–≥–∏–æ–Ω', '–°—Ç–∞—Ç—É—Å']] = [None, None, None, '‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ']
                    else:
                        final_result_df.loc[mask, '–ò—Ç–æ–≥–æ–≤–æ–µ –≥–µ–æ'] = new_value
                        if new_value in hh_areas:
                            final_result_df.loc[mask, 'ID HH'] = hh_areas[new_value]['id']
                            final_result_df.loc[mask, '–†–µ–≥–∏–æ–Ω'] = hh_areas[new_value]['parent']

            col1_dl, col2_dl, col3_dl = st.columns(3)
            # –ö–Ω–æ–ø–∫–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
            # ... (–ª–æ–≥–∏–∫–∞ –∫–Ω–æ–ø–æ–∫ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
            
    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞: {str(e)}")

st.markdown("---")
st.markdown("–°–¥–µ–ª–∞–Ω–æ —Å ‚ù§Ô∏è | –î–∞–Ω–Ω—ã–µ –∏–∑ API HH.ru")
