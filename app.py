import streamlit as st
import requests
import pandas as pd
from rapidfuzz import fuzz, process
import io

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(
    page_title="–°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –≥–æ—Ä–æ–¥–æ–≤ —Å HH.ru",
    page_icon="üåç",
    layout="wide"
)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è session_state
if 'result_df' not in st.session_state:
    st.session_state.result_df = None
if 'duplicate_count' not in st.session_state:
    st.session_state.duplicate_count = 0
if 'processed' not in st.session_state:
    st.session_state.processed = False
if 'manual_selections' not in st.session_state:
    st.session_state.manual_selections = {}
if 'candidates_cache' not in st.session_state:
    st.session_state.candidates_cache = {}

# ============================================
# –§–£–ù–ö–¶–ò–ò
# ============================================
@st.cache_data(ttl=3600)
def get_hh_areas():
    """–ü–æ–ª—É—á–∞–µ—Ç —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫ HH.ru"""
    response = requests.get('https://api.hh.ru/areas')
    data = response.json()
    
    areas_dict = {}
    
    def parse_areas(areas, parent_name=""):
        for area in areas:
            area_id = area['id']
            area_name = area['name']
            
            areas_dict[area_name] = {
                'id': area_id,
                'name': area_name,
                'parent': parent_name
            }
            
            if area.get('areas'):
                parse_areas(area['areas'], area_name)
    
    parse_areas(data)
    return areas_dict

def normalize_region_name(text):
    """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ —Ä–µ–≥–∏–æ–Ω–∞ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è"""
    text = text.lower()
    replacements = {
        '–ª–µ–Ω–∏–Ω–≥—Ä–∞–¥—Å–∫–∞—è': '–ª–µ–Ω–∏–Ω–≥—Ä–∞–¥',
        '–º–æ—Å–∫–æ–≤—Å–∫–∞—è': '–º–æ—Å–∫–æ–≤',
        '–∫—É—Ä—Å–∫–∞—è': '–∫—É—Ä—Å–∫',
        '–∫–µ–º–µ—Ä–æ–≤—Å–∫–∞—è': '–∫–µ–º–µ—Ä–æ–≤',
        '—Å–≤–µ—Ä–¥–ª–æ–≤—Å–∫–∞—è': '—Å–≤–µ—Ä–¥–ª–æ–≤',
        '–Ω–∏–∂–µ–≥–æ—Ä–æ–¥—Å–∫–∞—è': '–Ω–∏–∂–µ–≥–æ—Ä–æ–¥',
        '–Ω–æ–≤–æ—Å–∏–±–∏—Ä—Å–∫–∞—è': '–Ω–æ–≤–æ—Å–∏–±–∏—Ä—Å–∫',
        '—Ç–∞–º–±–æ–≤—Å–∫–∞—è': '—Ç–∞–º–±–æ–≤',
        '–∫—Ä–∞—Å–Ω–æ—è—Ä—Å–∫–∞—è': '–∫—Ä–∞—Å–Ω–æ—è—Ä—Å–∫',
        '–æ–±–ª–∞—Å—Ç—å': '',
        '–æ–±–ª': '',
        '–∫—Ä–∞–π': '',
        '—Ä–µ—Å–ø—É–±–ª–∏–∫–∞': '',
        '—Ä–µ—Å–ø': '',
        '  ': ' '
    }
    for old, new in replacements.items():
        text = text.replace(old, new)
    return text.strip()

def extract_city_and_region(text):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ –≥–æ—Ä–æ–¥–∞ –∏ —Ä–µ–≥–∏–æ–Ω–∞ –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
    text_lower = text.lower()
    
    region_keywords = [
        '–æ–±–ª–∞—Å—Ç', '–∫—Ä–∞–π', '—Ä–µ—Å–ø—É–±–ª–∏–∫', '–æ–∫—Ä—É–≥',
        '–ª–µ–Ω–∏–Ω–≥—Ä–∞–¥', '–º–æ—Å–∫–æ–≤', '–∫—É—Ä—Å–∫', '–∫–µ–º–µ—Ä–æ–≤',
        '—Å–≤–µ—Ä–¥–ª–æ–≤', '–Ω–∏–∂–µ–≥–æ—Ä–æ–¥', '–Ω–æ–≤–æ—Å–∏–±–∏—Ä—Å–∫', '—Ç–∞–º–±–æ–≤',
        '–∫—Ä–∞—Å–Ω–æ—è—Ä—Å–∫'
    ]
    
    words = text.split()
    
    if len(words) == 1:
        return text, None
    
    city_words = []
    region_words = []
    region_found = False
    
    for word in words:
        word_lower = word.lower()
        if not region_found and any(keyword in word_lower for keyword in region_keywords):
            region_found = True
            region_words.append(word)
        elif region_found:
            region_words.append(word)
        else:
            city_words.append(word)
    
    city = ' '.join(city_words) if city_words else text
    region = ' '.join(region_words) if region_words else None
    
    return city, region

def check_if_changed(original, matched):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –∏–∑–º–µ–Ω–∏–ª–æ—Å—å –ª–∏ –Ω–∞–∑–≤–∞–Ω–∏–µ –≥–æ—Ä–æ–¥–∞"""
    if matched is None or matched == "‚ùå –ù–µ—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è":
        return False
    
    original_clean = original.strip()
    matched_clean = matched.strip()
    
    return original_clean != matched_clean

def get_candidates_by_word(client_city, hh_city_names, limit=20):
    """–ü–æ–ª—É—á–∞–µ—Ç –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –ø–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—é –Ω–∞—á–∞–ª—å–Ω–æ–≥–æ —Å–ª–æ–≤–∞"""
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–µ—Ä–≤–æ–µ —Å–ª–æ–≤–æ –∏–∑ –≥–æ—Ä–æ–¥–∞
    first_word = client_city.split()[0].lower().strip()
    
    # –ò—â–µ–º –≤—Å–µ –≥–æ—Ä–æ–¥–∞, —Å–æ–¥–µ—Ä–∂–∞—â–∏–µ —ç—Ç–æ —Å–ª–æ–≤–æ
    candidates = []
    for city_name in hh_city_names:
        city_lower = city_name.lower()
        if first_word in city_lower:
            # –í—ã—á–∏—Å–ª—è–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –¥–ª—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏
            score = fuzz.WRatio(client_city.lower(), city_lower)
            candidates.append((city_name, score))
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –ø—Ä–æ—Ü–µ–Ω—Ç—É —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
    candidates.sort(key=lambda x: x[1], reverse=True)
    
    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
    return candidates[:limit]

def smart_match_city(client_city, hh_city_names, hh_areas, threshold=85):
    """–£–º–Ω–æ–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –≥–æ—Ä–æ–¥–∞ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤"""
    
    city_part, region_part = extract_city_and_region(client_city)
    city_part_lower = city_part.lower().strip()
    
    # –ü–æ–ª—É—á–∞–µ–º –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –ø–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—é —Å–ª–æ–≤–∞
    word_candidates = get_candidates_by_word(client_city, hh_city_names)
    
    exact_matches = []
    exact_matches_with_region = []
    
    for hh_city_name in hh_city_names:
        hh_city_base = hh_city_name.split('(')[0].strip().lower()
        
        if city_part_lower == hh_city_base:
            if region_part:
                region_normalized = normalize_region_name(region_part)
                hh_normalized = normalize_region_name(hh_city_name)
                
                if region_normalized in hh_normalized:
                    exact_matches_with_region.append(hh_city_name)
                else:
                    exact_matches.append(hh_city_name)
            else:
                exact_matches.append(hh_city_name)
    
    if exact_matches_with_region:
        best_match = exact_matches_with_region[0]
        score = fuzz.WRatio(client_city.lower(), best_match.lower())
        return (best_match, score, 0), word_candidates
    elif exact_matches:
        best_match = exact_matches[0]
        score = fuzz.WRatio(client_city.lower(), best_match.lower())
        return (best_match, score, 0), word_candidates
    
    candidates = process.extract(
        client_city,
        hh_city_names,
        scorer=fuzz.WRatio,
        limit=10
    )
    
    if not candidates:
        return None, word_candidates
    
    candidates = [c for c in candidates if c[1] >= threshold]
    
    if not candidates:
        return None, word_candidates
    
    if len(candidates) == 1:
        return candidates[0], word_candidates
    
    best_match = None
    best_score = 0
    
    client_city_lower = client_city.lower()
    
    for candidate_name, score, _ in candidates:
        candidate_lower = candidate_name.lower()
        adjusted_score = score
        
        candidate_city = candidate_name.split('(')[0].strip().lower()
        
        if city_part_lower == candidate_city:
            adjusted_score += 50
        elif city_part_lower in candidate_city:
            adjusted_score += 30
        elif candidate_city in city_part_lower:
            adjusted_score += 20
        else:
            adjusted_score -= 30
        
        if region_part:
            region_normalized = normalize_region_name(region_part)
            candidate_normalized = normalize_region_name(candidate_name)
            
            if region_normalized in candidate_normalized:
                adjusted_score += 40
            elif '(' in candidate_name:
                adjusted_score -= 25
        
        len_diff = abs(len(candidate_city) - len(city_part_lower))
        if len_diff > 3:
            adjusted_score -= 20
        
        if len(candidate_city) > len(city_part_lower) + 4:
            adjusted_score -= 25
        
        if len(candidate_name) > 15 and len(client_city) > 15:
            adjusted_score += 5
        
        region_keywords = ['–æ–±–ª–∞—Å—Ç', '–∫—Ä–∞–π', '—Ä–µ—Å–ø—É–±–ª–∏–∫', '–æ–∫—Ä—É–≥']
        client_has_region = any(keyword in client_city_lower for keyword in region_keywords)
        candidate_has_region = any(keyword in candidate_lower for keyword in region_keywords)
        
        if client_has_region and candidate_has_region:
            adjusted_score += 15
        elif client_has_region and not candidate_has_region:
            adjusted_score -= 15
        
        if adjusted_score > best_score:
            best_score = adjusted_score
            best_match = (candidate_name, score, _)
    
    return (best_match if best_match else candidates[0]), word_candidates

def match_cities(client_cities, hh_areas, threshold=85):
    """–°–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ—Ç –≥–æ—Ä–æ–¥–∞ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤"""
    results = []
    hh_city_names = list(hh_areas.keys())
    
    seen_original_cities = {}
    seen_hh_cities = {}
    
    duplicate_original_count = 0
    duplicate_hh_count = 0
    
    st.session_state.candidates_cache = {}
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    for idx, client_city in enumerate(client_cities):
        progress = (idx + 1) / len(client_cities)
        progress_bar.progress(progress)
        status_text.text(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {idx + 1} –∏–∑ {len(client_cities)} –≥–æ—Ä–æ–¥–æ–≤...")
        
        if pd.isna(client_city) or str(client_city).strip() == "":
            results.append({
                '–ò—Å—Ö–æ–¥–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ': client_city,
                '–ù–∞–∑–≤–∞–Ω–∏–µ HH': None,
                'ID HH': None,
                '–†–µ–≥–∏–æ–Ω': None,
                '–°–æ–≤–ø–∞–¥–µ–Ω–∏–µ %': 0,
                '–ò–∑–º–µ–Ω–µ–Ω–∏–µ': '–ù–µ—Ç',
                '–°—Ç–∞—Ç—É—Å': '‚ùå –ü—É—Å—Ç–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ',
                'row_id': idx
            })
            continue
        
        client_city_original = str(client_city).strip()
        client_city_normalized = client_city_original.lower().strip()
        
        if client_city_normalized in seen_original_cities:
            duplicate_original_count += 1
            original_result = seen_original_cities[client_city_normalized]
            results.append({
                '–ò—Å—Ö–æ–¥–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ': client_city_original,
                '–ù–∞–∑–≤–∞–Ω–∏–µ HH': original_result['–ù–∞–∑–≤–∞–Ω–∏–µ HH'],
                'ID HH': original_result['ID HH'],
                '–†–µ–≥–∏–æ–Ω': original_result['–†–µ–≥–∏–æ–Ω'],
                '–°–æ–≤–ø–∞–¥–µ–Ω–∏–µ %': original_result['–°–æ–≤–ø–∞–¥–µ–Ω–∏–µ %'],
                '–ò–∑–º–µ–Ω–µ–Ω–∏–µ': original_result['–ò–∑–º–µ–Ω–µ–Ω–∏–µ'],
                '–°—Ç–∞—Ç—É—Å': 'üîÑ –î—É–±–ª–∏–∫–∞—Ç (–∏—Å—Ö–æ–¥–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ)',
                'row_id': idx
            })
            continue
        
        match_result, candidates = smart_match_city(client_city_original, hh_city_names, hh_areas, threshold)
        
        st.session_state.candidates_cache[idx] = candidates
        
        if match_result:
            matched_name = match_result[0]
            score = match_result[1]
            hh_info = hh_areas[matched_name]
            hh_city_normalized = hh_info['name'].lower().strip()
            
            is_changed = check_if_changed(client_city_original, hh_info['name'])
            change_status = '–î–∞' if is_changed else '–ù–µ—Ç'
            
            if hh_city_normalized in seen_hh_cities:
                duplicate_hh_count += 1
                city_result = {
                    '–ò—Å—Ö–æ–¥–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ': client_city_original,
                    '–ù–∞–∑–≤–∞–Ω–∏–µ HH': hh_info['name'],
                    'ID HH': hh_info['id'],
                    '–†–µ–≥–∏–æ–Ω': hh_info['parent'],
                    '–°–æ–≤–ø–∞–¥–µ–Ω–∏–µ %': round(score, 1),
                    '–ò–∑–º–µ–Ω–µ–Ω–∏–µ': change_status,
                    '–°—Ç–∞—Ç—É—Å': 'üîÑ –î—É–±–ª–∏–∫–∞—Ç (—Ä–µ–∑—É–ª—å—Ç–∞—Ç HH)',
                    'row_id': idx
                }
                results.append(city_result)
                seen_original_cities[client_city_normalized] = city_result
            else:
                status = '‚úÖ –¢–æ—á–Ω–æ–µ' if score >= 95 else '‚ö†Ô∏è –ü–æ—Ö–æ–∂–µ–µ'
                
                city_result = {
                    '–ò—Å—Ö–æ–¥–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ': client_city_original,
                    '–ù–∞–∑–≤–∞–Ω–∏–µ HH': hh_info['name'],
                    'ID HH': hh_info['id'],
                    '–†–µ–≥–∏–æ–Ω': hh_info['parent'],
                    '–°–æ–≤–ø–∞–¥–µ–Ω–∏–µ %': round(score, 1),
                    '–ò–∑–º–µ–Ω–µ–Ω–∏–µ': change_status,
                    '–°—Ç–∞—Ç—É—Å': status,
                    'row_id': idx
                }
                
                results.append(city_result)
                seen_original_cities[client_city_normalized] = city_result
                seen_hh_cities[hh_city_normalized] = True
        else:
            city_result = {
                '–ò—Å—Ö–æ–¥–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ': client_city_original,
                '–ù–∞–∑–≤–∞–Ω–∏–µ HH': None,
                'ID HH': None,
                '–†–µ–≥–∏–æ–Ω': None,
                '–°–æ–≤–ø–∞–¥–µ–Ω–∏–µ %': 0,
                '–ò–∑–º–µ–Ω–µ–Ω–∏–µ': '–ù–µ—Ç',
                '–°—Ç–∞—Ç—É—Å': '‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ',
                'row_id': idx
            }
            
            results.append(city_result)
            seen_original_cities[client_city_normalized] = city_result
    
    progress_bar.empty()
    status_text.empty()
    
    total_duplicates = duplicate_original_count + duplicate_hh_count
    
    return pd.DataFrame(results), duplicate_original_count, duplicate_hh_count, total_duplicates

# ============================================
# –ò–ù–¢–ï–†–§–ï–ô–°
# ============================================
st.title("üåç –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –≥–æ—Ä–æ–¥–æ–≤ —Å HH.ru")
st.markdown("---")

with st.sidebar:
    st.header("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏")
    threshold = st.slider(
        "–ü–æ—Ä–æ–≥ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è (%)",
        min_value=50,
        max_value=100,
        value=85,
        help="–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø—Ä–æ—Ü–µ–Ω—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è"
    )
    
    st.markdown("---")
    st.markdown("### üìñ –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è")
    st.markdown("""
    1. –ó–∞–≥—Ä—É–∑–∏—Ç–µ Excel –∏–ª–∏ CSV
    2. –ì–æ—Ä–æ–¥–∞ –≤ –ø–µ—Ä–≤–æ–π –∫–æ–ª–æ–Ω–∫–µ
    3. –ù–∞–∂–º–∏—Ç–µ "–ù–∞—á–∞—Ç—å"
    4. –†–µ–¥–∞–∫—Ç–∏—Ä—É–π—Ç–µ –≥–æ—Ä–æ–¥–∞ —Å —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ–º < 86%
    5. –í—ã–±–µ—Ä–∏—Ç–µ "‚ùå –ù–µ—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è" –µ—Å–ª–∏ –≥–æ—Ä–æ–¥ –Ω–µ –ø–æ–¥—Ö–æ–¥–∏—Ç
    6. –°–∫–∞—á–∞–π—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    """)
    
    st.markdown("---")
    st.markdown("### üìä –°—Ç–∞—Ç—É—Å—ã")
    st.markdown("""
    - ‚úÖ **–¢–æ—á–Ω–æ–µ** - —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ ‚â•95%
    - ‚ö†Ô∏è **–ü–æ—Ö–æ–∂–µ–µ** - —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ ‚â•–ø–æ—Ä–æ–≥–∞
    - üîÑ **–î—É–±–ª–∏–∫–∞—Ç** - –ø–æ–≤—Ç–æ—Ä—ã
    - ‚ùå **–ù–µ –Ω–∞–π–¥–µ–Ω–æ** - —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ <–ø–æ—Ä–æ–≥–∞
    """)
    
    st.markdown("---")
    st.success("""
    ‚ú® **–ù–æ–≤–æ–µ v4.1:**
    
    **–£–ª—É—á—à–µ–Ω–Ω–æ–µ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ:**
    - –û–ø—Ü–∏—è "‚ùå –ù–µ—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è" - –≥–æ—Ä–æ–¥ –Ω–µ –ø–æ–ø–∞–¥–µ—Ç –≤ –≤—ã–≥—Ä—É–∑–∫—É
    - –ü–æ–∏—Å–∫ –ø–æ –Ω–∞—á–∞–ª—å–Ω–æ–º—É —Å–ª–æ–≤—É (–≤—Å–µ –≥–æ—Ä–æ–¥–∞ —Å —ç—Ç–∏–º —Å–ª–æ–≤–æ–º)
    - –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
    """)

col1, col2 = st.columns([1, 1])

with col1:
    st.subheader("üì§ –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞")
    uploaded_file = st.file_uploader(
        "–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–∞–π–ª —Å –≥–æ—Ä–æ–¥–∞–º–∏",
        type=['xlsx', 'csv'],
        help="–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è —Ñ–æ—Ä–º–∞—Ç—ã: Excel (.xlsx) –∏ CSV"
    )
    
    with st.expander("üìã –ü–æ–∫–∞–∑–∞—Ç—å –ø—Ä–∏–º–µ—Ä —Ñ–æ—Ä–º–∞—Ç–∞ —Ñ–∞–π–ª–∞"):
        example_df = pd.DataFrame({
            '–ì–æ—Ä–æ–¥': ['–ú–æ—Å–∫–≤–∞', '–ü–∏—Ç–µ—Ä', '–ï–∫–∞—Ç–µ—Ä–∏–Ω–±—É—Ä–≥', '–ù–æ–≤–æ—Å–∏–±']
        })
        st.dataframe(example_df, use_container_width=True)

with col2:
    st.subheader("‚ÑπÔ∏è –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è")
    try:
        hh_areas = get_hh_areas()
        st.success(f"‚úÖ –°–ø—Ä–∞–≤–æ—á–Ω–∏–∫ HH –∑–∞–≥—Ä—É–∂–µ–Ω: **{len(hh_areas)}** –≥–æ—Ä–æ–¥–æ–≤")
    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∞: {str(e)}")
        hh_areas = None

if uploaded_file is not None and hh_areas is not None:
    st.markdown("---")
    
    try:
        if uploaded_file.name.endswith('.csv'):
            df = pd.read_csv(uploaded_file)
        else:
            df = pd.read_excel(uploaded_file)
        
        client_cities = df.iloc[:, 0].tolist()
        st.info(f"üìÑ –ó–∞–≥—Ä—É–∂–µ–Ω–æ **{len(client_cities)}** –≥–æ—Ä–æ–¥–æ–≤ –∏–∑ —Ñ–∞–π–ª–∞")
        
        if st.button("üöÄ –ù–∞—á–∞—Ç—å —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ", type="primary", use_container_width=True):
            with st.spinner("–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é..."):
                result_df, dup_original, dup_hh, total_dup = match_cities(client_cities, hh_areas, threshold)
                st.session_state.result_df = result_df
                st.session_state.dup_original = dup_original
                st.session_state.dup_hh = dup_hh
                st.session_state.total_dup = total_dup
                st.session_state.processed = True
                st.session_state.manual_selections = {}
        
        if st.session_state.processed and st.session_state.result_df is not None:
            result_df = st.session_state.result_df.copy()
            dup_original = st.session_state.dup_original
            dup_hh = st.session_state.dup_hh
            total_dup = st.session_state.total_dup
            
            st.markdown("---")
            st.subheader("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã")
            
            col1, col2, col3, col4, col5, col6 = st.columns(6)
            
            total = len(result_df)
            exact = len(result_df[result_df['–°—Ç–∞—Ç—É—Å'] == '‚úÖ –¢–æ—á–Ω–æ–µ'])
            similar = len(result_df[result_df['–°—Ç–∞—Ç—É—Å'] == '‚ö†Ô∏è –ü–æ—Ö–æ–∂–µ–µ'])
            duplicates = len(result_df[result_df['–°—Ç–∞—Ç—É—Å'].str.contains('–î—É–±–ª–∏–∫–∞—Ç', na=False)])
            not_found = len(result_df[result_df['–°—Ç–∞—Ç—É—Å'] == '‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ'])
            changed = len(result_df[result_df['–ò–∑–º–µ–Ω–µ–Ω–∏–µ'] == '–î–∞'])
            
            col1.metric("–í—Å–µ–≥–æ", total)
            col2.metric("‚úÖ –¢–æ—á–Ω—ã—Ö", exact, f"{exact/total*100:.1f}%")
            col3.metric("‚ö†Ô∏è –ü–æ—Ö–æ–∂–∏—Ö", similar, f"{similar/total*100:.1f}%")
            col4.metric("üîÑ –î—É–±–ª–∏–∫–∞—Ç–æ–≤", duplicates, f"{duplicates/total*100:.1f}%")
            col5.metric("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ", not_found, f"{not_found/total*100:.1f}%")
            col6.metric("üîÑ –ò–∑–º–µ–Ω–µ–Ω–æ", changed, f"{changed/total*100:.1f}%")
            
            if duplicates > 0:
                st.warning(f"""
                ‚ö†Ô∏è **–ù–∞–π–¥–µ–Ω–æ {duplicates} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤:**
                - üîÑ –ü–æ –∏—Å—Ö–æ–¥–Ω–æ–º—É –Ω–∞–∑–≤–∞–Ω–∏—é: **{dup_original}**
                - üîÑ –ü–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—É HH: **{dup_hh}**
                """)
            
            st.markdown("---")
            st.subheader("üìã –¢–∞–±–ª–∏—Ü–∞ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–π")
            
            # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞
            result_df['sort_priority'] = result_df.apply(
                lambda row: 0 if row['–°–æ–≤–ø–∞–¥–µ–Ω–∏–µ %'] == 0 else (1 if row['–ò–∑–º–µ–Ω–µ–Ω–∏–µ'] == '–î–∞' else 2),
                axis=1
            )
            
            result_df_sorted = result_df.sort_values(
                by=['sort_priority', '–°–æ–≤–ø–∞–¥–µ–Ω–∏–µ %'],
                ascending=[True, True]
            ).reset_index(drop=True)
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –æ—Å–Ω–æ–≤–Ω—É—é —Ç–∞–±–ª–∏—Ü—É
            display_df = result_df_sorted.copy()
            display_df = display_df.drop(['row_id', 'sort_priority'], axis=1, errors='ignore')
            
            st.dataframe(display_df, use_container_width=True, height=400)
            
            # –†–∞–∑–¥–µ–ª –¥–ª—è —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –≥–æ—Ä–æ–¥–æ–≤ —Å —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ–º < 86%
            editable_rows = result_df_sorted[result_df_sorted['–°–æ–≤–ø–∞–¥–µ–Ω–∏–µ %'] < 86].copy()
            
            if len(editable_rows) > 0:
                st.markdown("---")
                st.subheader("‚úèÔ∏è –†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≥–æ—Ä–æ–¥–æ–≤ —Å —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ–º < 86%")
                st.info(f"–ù–∞–π–¥–µ–Ω–æ **{len(editable_rows)}** –≥–æ—Ä–æ–¥–æ–≤, –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –¥–ª—è —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
                
                # –°–æ–∑–¥–∞–µ–º —Ñ–æ—Ä–º—É –¥–ª—è —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
                for idx, row in editable_rows.iterrows():
                    with st.container():
                        col1, col2, col3, col4 = st.columns([2, 3, 1, 1])
                        
                        with col1:
                            st.markdown(f"**{row['–ò—Å—Ö–æ–¥–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ']}**")
                        
                        with col2:
                            # –ü–æ–ª—É—á–∞–µ–º –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
                            row_id = row['row_id']
                            candidates = st.session_state.candidates_cache.get(row_id, [])
                            
                            if candidates:
                                # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ –æ–ø—Ü–∏–π —Å –æ–ø—Ü–∏–µ–π "–ù–µ—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è"
                                options = ["‚ùå –ù–µ—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è"] + [f"{c[0]} ({c[1]:.1f}%)" for c in candidates]
                                
                                # –¢–µ–∫—É—â–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
                                current_value = row['–ù–∞–∑–≤–∞–Ω–∏–µ HH']
                                
                                # –ï—Å–ª–∏ –µ—Å—Ç—å —Ä—É—á–Ω–æ–π –≤—ã–±–æ—Ä, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ
                                if row_id in st.session_state.manual_selections:
                                    selected_value = st.session_state.manual_selections[row_id]
                                    if selected_value == "‚ùå –ù–µ—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è":
                                        default_idx = 0
                                    else:
                                        # –ò—â–µ–º –≤ —Å–ø–∏—Å–∫–µ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
                                        default_idx = 0
                                        for i, c in enumerate(candidates):
                                            if c[0] == selected_value:
                                                default_idx = i + 1  # +1 –ø–æ—Ç–æ–º—É —á—Ç–æ –ø–µ—Ä–≤–∞—è –æ–ø—Ü–∏—è "–ù–µ—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è"
                                                break
                                else:
                                    # –ù–∞—Ö–æ–¥–∏–º –∏–Ω–¥–µ–∫—Å —Ç–µ–∫—É—â–µ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è
                                    default_idx = 0
                                    if current_value:
                                        for i, c in enumerate(candidates):
                                            if c[0] == current_value:
                                                default_idx = i + 1
                                                break
                                
                                # Selectbox –¥–ª—è –≤—ã–±–æ—Ä–∞
                                selected = st.selectbox(
                                    "–í—ã–±–µ—Ä–∏—Ç–µ –≥–æ—Ä–æ–¥:",
                                    options=options,
                                    index=default_idx,
                                    key=f"select_{row_id}",
                                    label_visibility="collapsed"
                                )
                                
                                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—ã–±–æ—Ä
                                if selected == "‚ùå –ù–µ—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è":
                                    st.session_state.manual_selections[row_id] = "‚ùå –ù–µ—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è"
                                else:
                                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –≥–æ—Ä–æ–¥–∞ –±–µ–∑ –ø—Ä–æ—Ü–µ–Ω—Ç–∞
                                    selected_city = selected.rsplit(' (', 1)[0]
                                    st.session_state.manual_selections[row_id] = selected_city
                            else:
                                # –ï—Å–ª–∏ –Ω–µ—Ç –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤, –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –æ–ø—Ü–∏—é "–ù–µ—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è"
                                st.selectbox(
                                    "–ù–µ—Ç –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤",
                                    options=["‚ùå –ù–µ—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è"],
                                    index=0,
                                    key=f"select_{row_id}",
                                    label_visibility="collapsed",
                                    disabled=True
                                )
                                st.session_state.manual_selections[row_id] = "‚ùå –ù–µ—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è"
                        
                        with col3:
                            st.text(f"{row['–°–æ–≤–ø–∞–¥–µ–Ω–∏–µ %']}%")
                        
                        with col4:
                            st.text(row['–°—Ç–∞—Ç—É—Å'])
                        
                        st.markdown("---")
                
                if st.session_state.manual_selections:
                    # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å–∫–æ–ª—å–∫–æ –≥–æ—Ä–æ–¥–æ–≤ –æ—Ç–º–µ—á–µ–Ω–æ –∫–∞–∫ "–ù–µ—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è"
                    no_match_count = sum(1 for v in st.session_state.manual_selections.values() if v == "‚ùå –ù–µ—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è")
                    changed_count = len(st.session_state.manual_selections) - no_match_count
                    
                    st.success(f"‚úÖ –í–Ω–µ—Å–µ–Ω–æ –∏–∑–º–µ–Ω–µ–Ω–∏–π: {changed_count} | ‚ùå –û—Ç–º–µ—á–µ–Ω–æ –∫–∞–∫ '–ù–µ—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è': {no_match_count}")
            
            st.markdown("---")
            st.subheader("üíæ –°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã")
            
            col1, col2, col3 = st.columns(3)
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ä—É—á–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è
            final_result_df = result_df.copy()
            if st.session_state.manual_selections:
                for row_id, new_value in st.session_state.manual_selections.items():
                    mask = final_result_df['row_id'] == row_id
                    
                    if new_value == "‚ùå –ù–µ—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è":
                        # –ü–æ–º–µ—á–∞–µ–º –∫–∞–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω–Ω–æ–µ
                        final_result_df.loc[mask, '–ù–∞–∑–≤–∞–Ω–∏–µ HH'] = None
                        final_result_df.loc[mask, 'ID HH'] = None
                        final_result_df.loc[mask, '–†–µ–≥–∏–æ–Ω'] = None
                        final_result_df.loc[mask, '–°–æ–≤–ø–∞–¥–µ–Ω–∏–µ %'] = 0
                        final_result_df.loc[mask, '–ò–∑–º–µ–Ω–µ–Ω–∏–µ'] = '–ù–µ—Ç'
                        final_result_df.loc[mask, '–°—Ç–∞—Ç—É—Å'] = '‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ'
                    else:
                        # –ü—Ä–∏–º–µ–Ω—è–µ–º –≤—ã–±—Ä–∞–Ω–Ω—ã–π –≥–æ—Ä–æ–¥
                        final_result_df.loc[mask, '–ù–∞–∑–≤–∞–Ω–∏–µ HH'] = new_value
                        
                        if new_value in hh_areas:
                            final_result_df.loc[mask, 'ID HH'] = hh_areas[new_value]['id']
                            final_result_df.loc[mask, '–†–µ–≥–∏–æ–Ω'] = hh_areas[new_value]['parent']
                        
                        original = final_result_df.loc[mask, '–ò—Å—Ö–æ–¥–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ'].values[0]
                        final_result_df.loc[mask, '–ò–∑–º–µ–Ω–µ–Ω–∏–µ'] = '–î–∞' if check_if_changed(original, new_value) else '–ù–µ—Ç'
            
            # –ü–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç
            with col1:
                output = io.BytesIO()
                export_df = final_result_df.drop(['row_id', 'sort_priority'], axis=1, errors='ignore')
                with pd.ExcelWriter(output, engine='openpyxl') as writer:
                    export_df.to_excel(writer, index=False, sheet_name='–†–µ–∑—É–ª—å—Ç–∞—Ç')
                output.seek(0)
                
                st.download_button(
                    label="üì• –°–∫–∞—á–∞—Ç—å –ø–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç",
                    data=output,
                    file_name=f"result_{uploaded_file.name.rsplit('.', 1)[0]}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    use_container_width=True,
                    key='download_full'
                )
            
            # –§–∞–π–ª –¥–ª—è –ø—É–±–ª–∏–∫–∞—Ç–æ—Ä–∞ (–æ–±—ã—á–Ω—ã–π)
            with col2:
                unique_df = final_result_df[~final_result_df['–°—Ç–∞—Ç—É—Å'].str.contains('–î—É–±–ª–∏–∫–∞—Ç', na=False)]
                # –£–±–∏—Ä–∞–µ–º –≥–æ—Ä–æ–¥–∞ —Å "–ù–µ—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è"
                publisher_df = pd.DataFrame({'–ù–∞–∑–≤–∞–Ω–∏–µ HH': unique_df['–ù–∞–∑–≤–∞–Ω–∏–µ HH']})
                publisher_df = publisher_df.dropna()
                
                output_publisher = io.BytesIO()
                with pd.ExcelWriter(output_publisher, engine='openpyxl') as writer:
                    publisher_df.to_excel(writer, index=False, header=False, sheet_name='–ì–µ–æ')
                output_publisher.seek(0)
                
                unique_count = len(publisher_df)
                
                st.download_button(
                    label=f"üì§ –§–∞–π–ª –¥–ª—è –ø—É–±–ª–∏–∫–∞—Ç–æ—Ä–∞ ({unique_count})",
                    data=output_publisher,
                    file_name=f"geo_for_publisher_{uploaded_file.name.rsplit('.', 1)[0]}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    use_container_width=True,
                    key='download_publisher'
                )
            
            # –§–∞–π–ª —Å —Ä—É—á–Ω—ã–º–∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è–º–∏
            with col3:
                if st.session_state.manual_selections:
                    unique_manual_df = final_result_df[~final_result_df['–°—Ç–∞—Ç—É—Å'].str.contains('–î—É–±–ª–∏–∫–∞—Ç', na=False)]
                    publisher_manual_df = pd.DataFrame({'–ù–∞–∑–≤–∞–Ω–∏–µ HH': unique_manual_df['–ù–∞–∑–≤–∞–Ω–∏–µ HH']})
                    publisher_manual_df = publisher_manual_df.dropna()
                    
                    output_manual = io.BytesIO()
                    with pd.ExcelWriter(output_manual, engine='openpyxl') as writer:
                        publisher_manual_df.to_excel(writer, index=False, header=False, sheet_name='–ì–µ–æ')
                    output_manual.seek(0)
                    
                    manual_count = len(publisher_manual_df)
                    changes_count = len(st.session_state.manual_selections)
                    
                    st.download_button(
                        label=f"‚úèÔ∏è –° —Ä—É—á–Ω—ã–º–∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è–º–∏ ({changes_count} –∏–∑–º.)",
                        data=output_manual,
                        file_name=f"geo_manual_{uploaded_file.name.rsplit('.', 1)[0]}.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                        use_container_width=True,
                        type="primary",
                        key='download_manual'
                    )
                else:
                    st.info("–ù–µ—Ç —Ä—É—á–Ω—ã—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π")
    
    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞: {str(e)}")
        import traceback
        st.code(traceback.format_exc())

st.markdown("---")
st.markdown(
    "–°–¥–µ–ª–∞–Ω–æ —Å ‚ù§Ô∏è | –î–∞–Ω–Ω—ã–µ –∏–∑ API HH.ru | v4.1",
    unsafe_allow_html=True
)
